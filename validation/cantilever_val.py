"""
Dataset Generation
Topology Optimization of a Cantilever Beam
--------------------------------------------------------------------
Laboratory of Topology Optimization and Multiphysics Analysis
Department of Computational Mechanics
School of Mechanical Engineering
University of Campinas (Brazil)
--------------------------------------------------------------------
author  : Daniel Candeloro Cunha
version : 1.0
date    : May 2022
--------------------------------------------------------------------
To collaborate or report bugs, please look for the author's email
address at https://www.fem.unicamp.br/~ltm/

All codes and documentation are publicly available in the following
github repository: https://github.com/Joquempo/Cantilever-Dataset

If you use this program (or the data generated by it) in your work,
the developer would be grateful if you would cite the indicated
references. They are listed in the "CITEAS" file available in the
github repository.
--------------------------------------------------------------------
Copyright (C) 2022 Daniel Candeloro Cunha

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see https://www.gnu.org/licenses
"""

#%% Imports
import sys
import matplotlib.pyplot as plt
import matplotlib.collections as clct
import numpy as np
import dolfin as df
from scipy.sparse import coo_matrix
from sksparse.cholmod import analyze
from time import time

from dual import Dual
sys.path.append('./cython/')
from cgm import cgm_solve
from structural_bsens import str_cgs
from structural_ssens import str_ssens
from structural_filter import str_filter

#%% Setup

# fixed properties
rmax = 0.125   # sensitivity filter radius
Ey = 1.0       # Young's modulus
nu = 0.3       # Poisson's coefficient
epsk = 1e-6    # soft-kill parameter
Ly = 1.0       # cantilever height
small = 1e-14  # small value to compare float numbers

# input properties
Ny = 32
bc_pos = -0.250
bc_rad =  0.125
ld_pos =  0.250
ld_rad =  0.125

Nx = 2*Ny      # number of elements in x-axis
N = Nx*Ny      # total number of elements
esize = Ly/Ny  # element size
Lx = Nx*esize  # cantilever length

# topology vectors
x1 = np.ones(N,dtype=bool)
l0 = list(range(0,2017,32))
l1 = list(range(66,1955,32))
l2 = list(range(67,1956,32))
l3 = list(range(68,1957,32))
l4 = list(range(72,1961,32))
l5 = list(range(73,1962,32))
l6 = list(range(74,1963,32))
l7 = list(range(78,1967,32))
l8 = list(range(79,1968,32))
l9 = list(range(80,1969,32))
l10 = list(range(84,1973,32))
l11 = list(range(85,1974,32))
l12 = list(range(86,1975,32))
l13 = list(range(30,2047,32))
elist = l0 + l1 + l2 + l3 + l4 + l5 + l6 + l7 + l8 + l9 + l10 + l11 + l12 + l13
x1[elist] = False
x2 = 0.1 + 0.9*np.random.rand(N)

#%% Solver
print('[Solver]')
# Elemental Matrix (Quad4) - Plane Stress State
kk = (Ey/(1-nu**2))*np.array([ 1/2-nu/6 ,  1/8+nu/8, -1/4-nu/12, -1/8+3*nu/8,
                              -1/4+nu/12, -1/8-nu/8,      nu/6 ,  1/8-3*nu/8])
Ke = np.array([[kk[0],kk[1],kk[2],kk[3],kk[4],kk[5],kk[6],kk[7]],
               [kk[1],kk[0],kk[7],kk[6],kk[5],kk[4],kk[3],kk[2]],
               [kk[2],kk[7],kk[0],kk[5],kk[6],kk[3],kk[4],kk[1]],
               [kk[3],kk[6],kk[5],kk[0],kk[7],kk[2],kk[1],kk[4]],
               [kk[4],kk[5],kk[6],kk[7],kk[0],kk[1],kk[2],kk[3]],
               [kk[5],kk[4],kk[3],kk[2],kk[1],kk[0],kk[7],kk[6]],
               [kk[6],kk[3],kk[4],kk[1],kk[2],kk[7],kk[0],kk[5]],
               [kk[7],kk[2],kk[1],kk[4],kk[3],kk[6],kk[5],kk[0]]])
Kevec = Ke.ravel()
dKe = (1.0-epsk)*Ke  # stiffness variation of a topological change
# Elemental Matrix Factorizations
D,V = np.linalg.eigh(dKe)
mask = abs(D) > small
D = D[mask]
V = V[:,mask]
H = V*np.sqrt(D)
D,V = np.linalg.eigh(dKe[:,[2,3,4,5,6,7]][[2,3,4,5,6,7],:])
mask = abs(D) > small
D = D[mask]
V = V[:,mask]
H_01 = V*np.sqrt(D)
D,V = np.linalg.eigh(dKe[:,[0,1,2,3,4,5]][[0,1,2,3,4,5],:])
mask = abs(D) > small
D = D[mask]
V = V[:,mask]
H_67 = V*np.sqrt(D)
D,V = np.linalg.eigh(dKe[:,[2,3,4,5]][[2,3,4,5],:])
H_0167 = V*np.sqrt(D)
# coordinates matrix
xcoor = (Ny+1)*[list(range(Nx+1))]
xcoor = np.ravel(xcoor,'F')
ycoor = (Nx+1)*[list(range(Ny+1))]
ycoor = np.ravel(ycoor,'C')
coor = esize*np.array([xcoor,ycoor]).T
coor[:,1] = coor[:,1] - 0.5*Ly
# incidence matrix
N = Nx*Ny
G = 2*(Nx+1)*(Ny+1)
inci = np.ndarray([N,4],dtype=int)
elem_ids = np.arange(N)
inci[:,0] = elem_ids + elem_ids//Ny
inci[:,1] = inci[:,0] + Ny + 1
inci[:,2] = inci[:,0] + Ny + 2
inci[:,3] = inci[:,0] + 1
# free DOFs
bc_ycoor = coor[:Ny+1,1]
bc_mask = abs(bc_ycoor - bc_pos*Ly) < bc_rad*Ly + small
if sum(bc_mask) < 2:
    print('insufficient constraint')
    sys.exit()
bc_ids = np.arange(0,Ny+1)
bc_ids = bc_ids[bc_mask]
bc_lim = np.array([bc_ids[0],bc_ids[-1]],dtype="int64")
bc = np.concatenate((2*bc_ids,2*bc_ids+1))
freeDofs = np.ones(G,dtype=bool)
freeDofs[bc] = False
sys_size = sum(freeDofs)
# load vector
fg = np.zeros(G)
ld_ycoor = coor[Nx*(Ny+1):,1]
ld_mask = abs(ld_ycoor - ld_pos*Ly) < ld_rad*Ly + small
ld_mask_ele = ld_mask[1:] | ld_mask[:-1]
ld_ele = np.arange((Nx-1)*Ny,Nx*Ny)
ld_ele = ld_ele[ld_mask_ele]
ld_lim = np.array([ld_ele[0],ld_ele[-1]],dtype="int64")
ld_num = sum(ld_mask)
ld_ids = np.arange(Nx*(Ny+1),(Nx+1)*(Ny+1))
ld_ids = ld_ids[ld_mask]
if ld_num == 0:
    pass
elif ld_num == 1:
    fg[2*ld_ids+1] = -1.0
else:
    ld_val = -1.0/(ld_num-1)
    fg[2*ld_ids[1:-1]+1] = ld_val    
    fg[2*ld_ids[[0,-1]]+1] = 0.5*ld_val
fr = fg[freeDofs]
# COO data
pen1 = np.ones(N)
pen1[~x1] = epsk
pen1 = pen1.repeat(64)
data1 = pen1*np.tile(Kevec,N)
pen2 = epsk + (1.0-epsk)*(x2)
pen2 = pen2.repeat(64)
data2 = pen2*np.tile(Kevec,N)
# COO indices
dof0 = 2*inci[:,0]
dof1 = dof0 + 1
dof2 = 2*inci[:,1]
dof3 = dof2 + 1
dof4 = 2*inci[:,2]
dof5 = dof4 + 1
dof6 = 2*inci[:,3]
dof7 = dof6 + 1
eledofs = np.array([dof0,dof1,dof2,dof3,dof4,dof5,dof6,dof7])
row = eledofs.repeat(8,axis=0).ravel('F')
col = eledofs.T.repeat(8,axis=0).ravel('C')
# stiffness matrix
Kg_coo1 = coo_matrix((data1,(row,col)),shape=(G,G))
Kg_csc1 = Kg_coo1.tocsc()
Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
Kg_coo2 = coo_matrix((data2,(row,col)),shape=(G,G))
Kg_csc2 = Kg_coo2.tocsc()
Kr2 = Kg_csc2[freeDofs,:][:,freeDofs]
ug1 = np.zeros(G)
ug2 = np.zeros(G)
# call solver
t0 = time()
factor1 = analyze(Kr1)
factor1.cholesky_inplace(Kr1)
ug1[freeDofs] = factor1(fr)
t1 = time()
print('> scikit-sparse solver : {:.1e} s'.format(t1-t0))
t0 = time()
factor2 = analyze(Kr2)
factor2.cholesky_inplace(Kr2)
ug2[freeDofs] = factor2(fr)
t1 = time()
print('> scikit-sparse solver : {:.1e} s'.format(t1-t0))
# ======================================================================
# subdomains for boundary conditions
class left(df.SubDomain): # rotated to correct mesh numbering
    def __init__(self, point, radius):
        super().__init__()
        self.point = point
        self.radius = radius
    def inside(self, pos, on_boundary):
        return df.near(pos[1], 0.0, eps=small) and df.near(pos[0], self.point, eps=self.radius+small) and on_boundary
class right(df.SubDomain): # rotated to correct mesh numbering
    def __init__(self, point, radius, xlen):
        super().__init__()
        self.point = point
        self.radius = radius
        self.xlen = xlen
    def inside(self, pos, on_boundary):
        return df.near(pos[1], self.xlen, eps=small) and df.near(pos[0], self.point, eps=self.radius+small) and on_boundary
# rectangular mesh (rotated to correct mesh numbering)
mesh = df.RectangleMesh.create([df.Point(-0.5*Ly,0.0),df.Point(0.5*Ly,Lx)],[Ny,Nx],df.CellType.Type.quadrilateral)
# discontinuous density map (constant inside each element)
F0 = df.FunctionSpace(mesh, "DG", 0)
# bilinear quadrilateral finite elements
V1 = df.VectorFunctionSpace(mesh, "CG", 1)
# density map
dens = df.Function(F0)
dens.vector().set_local(x1)
dens.vector().apply("insert")
# isotropic material in stress plane state
Ey = df.Constant(Ey)
nu = df.Constant(nu)
E = epsk*Ey + dens*(1.0-epsk)*Ey
mu = E/(2*(1+nu))
lbd = E*nu/((1+nu)*(1-2*nu))
lbd = (2*mu*lbd)/(lbd+2*mu) # plane stress
# Dirichlet boundary conditions
dbound = left(Ly*bc_pos, Ly*bc_rad)
bc = [df.DirichletBC(V1.sub(0),df.Constant(0.0),dbound),df.DirichletBC(V1.sub(1),df.Constant(0.0),dbound)]
# internal residue
utest = df.TestFunction(V1)
utrial = df.TrialFunction(V1)
strain = df.sym(df.grad(utrial))
stress = lbd*df.div(utest)*df.Identity(2) + 2*mu*df.sym(df.grad(utest))
res_int = df.inner(stress,strain)*df.dx
# external residue
dload = right(Ly*ld_pos, max([Ly*ld_rad,esize]), Lx)
edges = df.MeshFunction("size_t", mesh, 1)
dload.mark(edges,1)
true_area = sum(edges.array())*esize         # considering square elements
load_value = np.array([-1.0,0.0])/true_area  # correction so that the input is the total load (rotated to correct mesh numbering)
ds = df.Measure("ds", subdomain_data=edges)
res_ext = df.dot(df.Constant(load_value),utest)*ds(1)
# displacements field
u = df.Function(V1)
# solve system
t0 = time()
df.solve(res_int == res_ext, u, bc)
t1 = time()
stime = np.float32(t1-t0)
uval = u.compute_vertex_values()
g = uval.shape[0]
uref = np.zeros(g)
uref[0::2] = uval[g//2:]
uref[1::2] = uval[:g//2]
uref1 = uref.astype(np.float32)
print('> fenics solver        : {:.1e} s'.format(t1-t0))
dens.vector().set_local(x2)
dens.vector().apply("insert")
t0 = time()
df.solve(res_int == res_ext, u, bc)
t1 = time()
stime = np.float32(t1-t0)
uval = u.compute_vertex_values()
g = uval.shape[0]
uref = np.zeros(g)
uref[0::2] = uval[g//2:]
uref[1::2] = uval[:g//2]
uref2 = uref.astype(np.float32)
print('> fenics solver        : {:.1e} s'.format(t1-t0))
print('> > relative error (discrete)   : {:.4f} %'.format(100*max(abs(uref1-ug1))/max(abs(uref1))))
print('> > relative error (continuous) : {:.4f} %'.format(100*max(abs(uref2-ug2))/max(abs(uref2))))
print('======================================================================')
# ======================================================================
# plots
xcoor = (Ny+1)*[list(range(Nx+2+1))]
xcoor = np.ravel(xcoor,'F')
ycoor = (Nx+2+1)*[list(range(Ny+1))]
ycoor = np.ravel(ycoor,'C')
gcoor = esize*np.array([xcoor,ycoor]).T
gcoor[:,1] = gcoor[:,1] - 0.5*Ly
gN = (Nx+2)*Ny
ginci = np.ndarray([gN,4],dtype=int)
elem_ids = np.arange(gN)
ginci[:,0] = elem_ids + elem_ids//Ny
ginci[:,1] = ginci[:,0] + Ny + 1
ginci[:,2] = ginci[:,0] + Ny + 2
ginci[:,3] = ginci[:,0] + 1
ycoor = esize*np.array(list(range(Ny+1)))-0.5*Ly
mask = (ycoor > bc_pos-bc_rad-small) & (ycoor < bc_pos+bc_rad+small)
c0 = np.zeros((32,1))
c0[mask[1:]]  += 0.25 
c0[mask[:-1]] += 0.25
mask = (ycoor > ld_pos-ld_rad-small) & (ycoor < ld_pos+ld_rad+small)
c1 = np.zeros((32,1))
c1[mask[1:]]  += 0.25 
c1[mask[:-1]] += 0.25
plt.figure(num=0).clear()
fig,ax = plt.subplots(nrows=2,ncols=2,num=0)
xmat = np.reshape(x1,(Ny,Nx),order='F')
xmat = np.concatenate((c0,xmat,c1),axis=1)
ax[0,0].imshow(xmat,cmap='gray_r',vmin=0,vmax=1.0,origin='lower')
ax[0,0].axis('off')
xmat = np.reshape(x2,(Ny,Nx),order='F')
xmat = np.concatenate((c0,xmat,c1),axis=1)
ax[1,0].imshow(xmat,cmap='gray_r',vmin=0,vmax=1.0,origin='lower')
ax[1,0].axis('off')
scale = 0.50*Ly/max(abs(ug1))
ugp1 = np.concatenate((ug1[:66],ug1,ug1[-66:]))
umat1 = np.reshape(ugp1,gcoor.shape)
coor_dis1 = gcoor + scale*umat1
xmax = max(coor_dis1[:,0])
xmin = min(coor_dis1[:,0])
ymax = max(coor_dis1[:,1])
ymin = min(coor_dis1[:,1])
Dx = xmax-xmin
Dy = ymax-ymin
polys = clct.PolyCollection(coor_dis1[ginci],cmap='gray_r',edgecolor=(0,0,0,0))
x = np.concatenate((c0[:,0],x1,c1[:,0]))
polys.set_array(x)
polys.set_clim(0.0,1.0)
ax[0,1].add_collection(polys)
ax[0,1].set_aspect('equal')
ax[0,1].set_xlim([xmin-0.01*Dx,xmax+0.01*Dx])
ax[0,1].set_ylim([ymin-0.01*Dy,ymax+0.01*Dy])
ax[0,1].axis('off')
scale = 0.50*Ly/max(abs(ug2))
ugp2 = np.concatenate((ug2[:66],ug2,ug2[-66:]))
umat2 = np.reshape(ugp2,gcoor.shape)
coor_dis2 = gcoor + scale*umat2
xmax = max(coor_dis2[:,0])
xmin = min(coor_dis2[:,0])
ymax = max(coor_dis2[:,1])
ymin = min(coor_dis2[:,1])
Dx = xmax-xmin
Dy = ymax-ymin
polys = clct.PolyCollection(coor_dis2[ginci],cmap='gray_r',edgecolor=(0,0,0,0))
x = np.concatenate((c0[:,0],x2,c1[:,0]))
polys.set_array(x)
polys.set_clim(0.0,1.0)
ax[1,1].add_collection(polys)
ax[1,1].set_aspect('equal')
ax[1,1].set_xlim([xmin-0.01*Dx,xmax+0.01*Dx])
ax[1,1].set_ylim([ymin-0.01*Dy,ymax+0.01*Dy])
ax[1,1].axis('off')

#%% Factorized Matrix Update
print('[Factorized Matrix Update]')
x = np.ones(N,dtype=bool)
pen = np.ones(N)
pen[~x] = epsk
pen = pen.repeat(64)
data = pen*np.tile(Kevec,N)
Kg_coo = coo_matrix((data,(row,col)),shape=(G,G))
Kg_csc = Kg_coo.tocsc()
Kr = Kg_csc[freeDofs,:][:,freeDofs]
ug = np.zeros(G)
factor = analyze(Kr)
t0 = time()
factor.cholesky_inplace(Kr)
t1 = time()
print('> factorization  : {:.1e} s'.format(t1-t0))
t0 = time()
for repeat in range(100):
    np.random.shuffle(elist)
    for i in elist:
        # update Cholesky factor (faster for coarse meshes)
        n0 = i + (i // Ny)
        n1 = n0 + Ny + 1
        n2 = n1 + 1
        n3 = n0 + 1
        nodes = np.array([n0,n1,n2,n3])
        freeNodes = (nodes < bc_lim[0]) | (nodes > bc_lim[1])
        nodes = nodes[freeNodes]
        mask = nodes > bc_lim[1]
        nodes[mask] = nodes[mask] - (bc_lim[1]-bc_lim[0]+1)
        gv = np.repeat(2*nodes,2)
        gv[1::2] = gv[1::2] + 1
        lgv = len(gv)
        rank = 5
        if all(freeNodes):
            hdata = H.ravel()
        elif (not freeNodes[0]) and (freeNodes[-1]):
            hdata = H_01.ravel()
        elif (freeNodes[0]) and (not freeNodes[-1]):
            hdata = H_67.ravel()
        else:
            hdata = H_0167.ravel()
            rank = 4
        hrow  = np.repeat(gv,rank)
        hcol  = np.tile(np.arange(rank),lgv)
        H_coo = coo_matrix((hdata,(hrow,hcol)),shape=(sys_size,rank))
        H_csc = H_coo.tocsc()    
        factor.update_inplace(H_csc, subtract=True)
    np.random.shuffle(elist)
    for i in elist:
        n0 = i + (i // Ny )
        n1 = n0 + Ny + 1
        n2 = n1 + 1
        n3 = n0 + 1
        nodes = np.array([n0,n1,n2,n3])
        freeNodes = (nodes < bc_lim[0]) | (nodes > bc_lim[1])
        nodes = nodes[freeNodes]
        mask = nodes > bc_lim[1]
        nodes[mask] = nodes[mask] - (bc_lim[1]-bc_lim[0]+1)
        gv = np.repeat(2*nodes,2)
        gv[1::2] = gv[1::2] + 1
        lgv = len(gv)
        rank = 5
        if all(freeNodes):
            hdata = H.ravel()
        elif (not freeNodes[0]) and (freeNodes[-1]):
            hdata = H_01.ravel()
        elif (freeNodes[0]) and (not freeNodes[-1]):
            hdata = H_67.ravel()
        else:
            hdata = H_0167.ravel()
            rank = 4
        hrow  = np.repeat(gv,rank)
        hcol  = np.tile(np.arange(rank),lgv)
        H_coo = coo_matrix((hdata,(hrow,hcol)),shape=(sys_size,rank))
        H_csc = H_coo.tocsc()     
        factor.update_inplace(H_csc, subtract=False)
t1 = time()
print('> average update : {:.1e} s (to alter {:.1f}% of the elements)'.format((t1-t0)/200,100*len(elist)/len(x)))
np.random.shuffle(elist)
for i in elist:
    n0 = i + (i // Ny)
    n1 = n0 + Ny + 1
    n2 = n1 + 1
    n3 = n0 + 1
    nodes = np.array([n0,n1,n2,n3])
    freeNodes = (nodes < bc_lim[0]) | (nodes > bc_lim[1])
    nodes = nodes[freeNodes]
    mask = nodes > bc_lim[1]
    nodes[mask] = nodes[mask] - (bc_lim[1]-bc_lim[0]+1)
    gv = np.repeat(2*nodes,2)
    gv[1::2] = gv[1::2] + 1
    lgv = len(gv)
    rank = 5
    if all(freeNodes):
        hdata = H.ravel()
    elif (not freeNodes[0]) and (freeNodes[-1]):
        hdata = H_01.ravel()
    elif (freeNodes[0]) and (not freeNodes[-1]):
        hdata = H_67.ravel()
    else:
        hdata = H_0167.ravel()
        rank = 4
    hrow  = np.repeat(gv,rank)
    hcol  = np.tile(np.arange(rank),lgv)
    H_coo = coo_matrix((hdata,(hrow,hcol)),shape=(sys_size,rank))
    H_csc = H_coo.tocsc()    
    factor.update_inplace(H_csc, subtract=True)
ug[freeDofs] = factor(fr)
print('> > relative error : {:.4f} %'.format(100*max(abs(ug-ug1))/max(abs(ug1))))
print('======================================================================')

#%% Sensitivity Values
print('[Sensitivity Values]')
alpha_s = np.zeros(N)        # SIMP
alpha_0 = np.zeros(N)        # CGS-0
alpha_1 = np.zeros(N)        # CGS-1
alpha_2 = np.zeros(N)        # CGS-2
alpha_w = np.zeros(N)        # WS
fe = np.zeros((sys_size,5))  # auxiliary matrix for WS approach
print('> SIMP sensitivity validation...')
str_ssens(alpha_s, x2, dKe, ug2, 1.0, Nx, Ny, serial=True)
alpha_sr = np.zeros(N)
xd = Dual(x2,np.zeros(N))
fd = Dual(fg,np.zeros(G))
pend = epsk + (1.0-epsk)*xd
pend = pend.repeat(64)
datad = pend*np.tile(Kevec,N)
ud,fac = Dual.solver(fd,datad,row,col,G,freeDofs)
for e in range(N):
    xd.epsl[e] = 1.0
    pend = epsk + (1.0-epsk)*xd
    pend = pend.repeat(64)
    datad = pend*np.tile(Kevec,N)
    ud,fac = Dual.solver(fd,datad,row,col,G,freeDofs,ud.real,fac)
    alpha_sr[e] = (ud @ fd).epsl
    xd.epsl[e] = 0.0
print('> > relative error (SIMP)  : {:.4f} %'.format(100*max(abs(alpha_s-alpha_sr))/max(abs(alpha_sr))))
print('> CGS validation...')
str_cgs(alpha_0, x1, Kg_csc1, bc_lim, dKe, ug1, Nx, Ny, steps=0, serial=True)
str_cgs(alpha_1, x1, Kg_csc1, bc_lim, dKe, ug1, Nx, Ny, steps=1, precond="J", serial=True)
str_cgs(alpha_2, x1, Kg_csc1, bc_lim, dKe, ug1, Nx, Ny, steps=2, precond="J", serial=True)
alpha_0r = np.zeros(N)
alpha_1r = np.zeros(N)
alpha_2r = np.zeros(N)
for e in range(N):
    col = e // Ny
    n0 = e + col
    n1 = e + col + Ny + 1
    n2 = e + col + Ny + 2
    n3 = e + col + 1
    nodes = np.array([n0,n1,n2,n3])
    gv = np.repeat(2*nodes,2)
    gv[1::2] = gv[1::2] + 1
    if x1[e]:
        x1[e] = False
        Kg_coo1.data[64*e:64*(e+1)] = epsk*Kevec
        Kg_csc1 = Kg_coo1.tocsc()
        Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=0)
        aux[freeDofs] = auxx
        alpha_0r[e] = -aux[gv] @ dKe @ ug1[gv]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=1, precond="J")
        aux[freeDofs] = auxx
        alpha_1r[e] = -aux[gv] @ dKe @ ug1[gv]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=2, precond="J")
        aux[freeDofs] = auxx
        alpha_2r[e] = -aux[gv] @ dKe @ ug1[gv]
        x1[e] = True
        Kg_coo1.data[64*e:64*(e+1)] = Kevec
    else:
        x1[e] = True
        Kg_coo1.data[64*e:64*(e+1)] = Kevec
        Kg_csc1 = Kg_coo1.tocsc()
        Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=0)
        aux[freeDofs] = auxx
        alpha_0r[e] = -aux[gv] @ dKe @ ug1[gv]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=1, precond="J")
        aux[freeDofs] = auxx
        alpha_1r[e] = -aux[gv] @ dKe @ ug1[gv]
        aux = ug1.copy()
        auxx = aux[freeDofs]
        cgm_solve(auxx, Kr1, fr, sum(freeDofs), steps=2, precond="J")
        aux[freeDofs] = auxx
        alpha_2r[e] = -aux[gv] @ dKe @ ug1[gv]
        x1[e] = False
        Kg_coo1.data[64*e:64*(e+1)] = epsk*Kevec
Kg_csc1 = Kg_coo1.tocsc()
Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
factor1.cholesky_inplace(Kr1)
print('> > relative error (CGS-0) : {:.4f} %'.format(100*max(abs(alpha_0-alpha_0r))/max(abs(alpha_0r))))
print('> > relative error (CGS-1) : {:.4f} %'.format(100*max(abs(alpha_1-alpha_1r))/max(abs(alpha_1r))))
print('> > relative error (CGS-2) : {:.4f} %'.format(100*max(abs(alpha_2-alpha_2r))/max(abs(alpha_2r))))
print('> WS validation...')
ur = ug1[freeDofs]
for e in range(N):
    n0 = e + (e // Ny)
    n1 = n0 + Ny + 1
    n2 = n1 + 1
    n3 = n0 + 1
    nodes = np.array([n0,n1,n2,n3])
    freeNodes = (nodes < bc_lim[0]) | (nodes > bc_lim[1])
    nodes = nodes[freeNodes]
    mask = nodes > bc_lim[1]
    nodes[mask] = nodes[mask] - (bc_lim[1]-bc_lim[0]+1)
    gv = np.repeat(2*nodes,2)
    gv[1::2] = gv[1::2] + 1
    rank = 5
    if all(freeNodes):
        He = H
    elif (not freeNodes[0]) and (freeNodes[-1]):
        He = H_01
    elif (freeNodes[0]) and (not freeNodes[-1]):
        He = H_67
    else:
        He = H_0167
        rank = 4
    Ai = np.zeros((rank,rank))
    fe[gv,:rank] = He
    aux = factor1.solve_L(factor1.apply_P(fe[:,:rank]),use_LDLt_decomposition=False)
    fe[gv,:rank] = 0.0
    Ai = aux.T @ aux
    vi = He.T @ ur[gv]
    Ii = np.identity(rank)
    if x1[e]:
        alpha_w[e] = -vi @ np.linalg.inv(Ii-Ai) @ vi
    else:
        alpha_w[e] = -vi @ np.linalg.inv(Ii+Ai) @ vi
aux = np.zeros(G)
alpha_wr = np.zeros(N)
for e in np.arange(N):
    col = e // Ny
    n0 = e + col
    n1 = e + col + Ny + 1
    n2 = e + col + Ny + 2
    n3 = e + col + 1
    nodes = np.array([n0,n1,n2,n3])
    gv = np.repeat(2*nodes,2)
    gv[1::2] = gv[1::2] + 1
    if x1[e]:
        x1[e] = False
        Kg_coo1.data[64*e:64*(e+1)] = epsk*Kevec
        Kg_csc1 = Kg_coo1.tocsc()
        Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
        factor1.cholesky_inplace(Kr1)
        aux[freeDofs] = factor1(fr)
        alpha_wr[e] = -aux[gv] @ dKe @ ug1[gv]
        x1[e] = True
        Kg_coo1.data[64*e:64*(e+1)] = Kevec
    else:
        x1[e] = True
        Kg_coo1.data[64*e:64*(e+1)] = Kevec
        Kg_csc1 = Kg_coo1.tocsc()
        Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
        factor1.cholesky_inplace(Kr1)
        aux[freeDofs] = factor1(fr)
        alpha_wr[e] = -aux[gv] @ dKe @ ug1[gv]
        x1[e] = False
        Kg_coo1.data[64*e:64*(e+1)] = epsk*Kevec
Kg_csc1 = Kg_coo1.tocsc()
Kr1 = Kg_csc1[freeDofs,:][:,freeDofs]
factor1.cholesky_inplace(Kr1)
print('> > relative error (WS)    : {:.4f} %'.format(100*max(abs(alpha_w-alpha_wr))/max(abs(alpha_wr))))
print('======================================================================')

#%% Conical Filter
print('[Conical Filter]')
fil = np.zeros(N)
raw = np.zeros(N)
pos = np.random.randint(0,Ny,Nx)
pos = pos + Ny*np.arange(Nx)
raw[pos] = 1.0
str_filter(raw, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
raw_0 = raw.copy()
fil_00 = fil.copy()
str_filter(raw, fil, rmax, esize, Nx, Ny, serial=True)
fil_01 = fil.copy()
raw = np.zeros(N)
raw[:Ny] = 1.0
raw[(Nx-1)*Ny:] = 1.0
raw[0::Ny] = 1.0
raw[Ny-1::Ny] = 1.0
str_filter(raw, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
raw_1 = raw.copy()
fil_10 = fil.copy()
str_filter(raw, fil, rmax, esize, Nx, Ny, serial=True)
fil_11 = fil.copy()
raw = np.zeros(N)
raw[Ny+1:2*Ny-1] = 1.0
raw[(Nx-2)*Ny+1:(Nx-1)*Ny-1] = 1.0
raw[Ny+1:(Nx-1)*Ny:Ny] = 1.0
raw[2*Ny-2:(Nx-1)*Ny:Ny] = 1.0
str_filter(raw, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
raw_2 = raw.copy()
fil_20 = fil.copy()
str_filter(raw, fil, rmax, esize, Nx, Ny, serial=True)
fil_21 = fil.copy()
# ======================================================================
# plots
plt.figure(num=1).clear()
fig,ax = plt.subplots(nrows=5,ncols=2,num=1)
mval = max(abs(alpha_s))
alpha = alpha_s/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[0,0].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[0,0].axis('off')
str_filter(alpha_s, fil, rmax, esize, Nx, Ny, serial=True)
alpha = fil/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[0,1].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[0,1].axis('off')
mval = max([max(abs(alpha_0)),max(abs(alpha_1)),max(abs(alpha_2)),max(abs(alpha_w))])
alpha = alpha_0/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[1,0].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[1,0].axis('off')
str_filter(alpha_0, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
alpha = fil/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[1,1].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[1,1].axis('off')
alpha = alpha_1/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[2,0].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[2,0].axis('off')
str_filter(alpha_1, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
alpha = fil/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[2,1].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[2,1].axis('off')
alpha = alpha_2/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[3,0].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[3,0].axis('off')
str_filter(alpha_2, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
alpha = fil/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[3,1].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[3,1].axis('off')
alpha = alpha_w/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[4,0].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[4,0].axis('off')
str_filter(alpha_w, fil, rmax, esize, Nx, Ny, load_lim=ld_lim, serial=True)
alpha = fil/mval
amat = np.reshape(np.log(-alpha+1e-6),(Ny,Nx),order='F')
ax[4,1].imshow(amat,cmap='jet',vmin=np.log(1e-6),vmax=np.log(1.0+1e-6),origin='lower')
ax[4,1].axis('off')
# ======================================================================
plt.figure(num=2).clear()
fig,ax = plt.subplots(nrows=3,ncols=3,num=2)
alpha = raw_0
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[0,0].imshow(amat,cmap='jet',vmin=min(raw_0),vmax=max(raw_0),origin='lower')
ax[0,0].axis('off')
alpha = fil_00
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[0,1].imshow(amat,cmap='jet',vmin=min(raw_0),vmax=max(raw_0),origin='lower')
ax[0,1].axis('off')
alpha = fil_01
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[0,2].imshow(amat,cmap='jet',vmin=min(raw_0),vmax=max(raw_0),origin='lower')
ax[0,2].axis('off')
alpha = raw_1
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[1,0].imshow(amat,cmap='jet',vmin=min(raw_1),vmax=max(raw_1),origin='lower')
ax[1,0].axis('off')
alpha = fil_10
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[1,1].imshow(amat,cmap='jet',vmin=min(raw_1),vmax=max(raw_1),origin='lower')
ax[1,1].axis('off')
alpha = fil_11
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[1,2].imshow(amat,cmap='jet',vmin=min(raw_1),vmax=max(raw_1),origin='lower')
ax[1,2].axis('off')
alpha = raw_2
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[2,0].imshow(amat,cmap='jet',vmin=min(raw_2),vmax=max(raw_2),origin='lower')
ax[2,0].axis('off')
alpha = fil_20
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[2,1].imshow(amat,cmap='jet',vmin=min(raw_2),vmax=max(raw_2),origin='lower')
ax[2,1].axis('off')
alpha = fil_21
amat = np.reshape(alpha,(Ny,Nx),order='F')
ax[2,2].imshow(amat,cmap='jet',vmin=min(raw_2),vmax=max(raw_2),origin='lower')
ax[2,2].axis('off')
print('======================================================================')
print('done!')